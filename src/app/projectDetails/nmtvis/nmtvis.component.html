<img src="./assets/images/projects/nmtvis.png">
<p>
    Quantities of machine translation models under the category of Neural Machine Translation
    (<a href="https://en.wikipedia.org/wiki/Neural_machine_translation" target="_blank"
        rel="noopener noreferrer">NMT</a>)
    have been designed in recent years. While these models can give extraordinary translations,
    they are always hard to understand and debug due to neural networks' lack of interpretability.
</p>
<p>
    To this end, I developed an open-sourced visualization toolkit
    <a href="https://pypi.org/project/nmtvis/" target="_blank" rel="noopener noreferrer">nmtvis</a>
    for visualizing three key mechanisms in NMT models: attention mechanism
    (<a href="https://player-eric.com/resources/nmtvis-demos/attention_demo" target="_blank"
        rel="noopener noreferrer">demo</a>)
    , word embedding
    (<a href="https://player-eric.com/resources/nmtvis-demos/embedding_demo" target="_blank"
        rel="noopener noreferrer">demo</a>)
    ,
    and beam search decoding
    (<a href="https://player-eric.com/resources/nmtvis-demos/beam_demo" target="_blank"
        rel="noopener noreferrer">demo</a>).
    It is published to PyPI and the source code is available
    <a href="https://github.com/player-eric/NMT-Visualizer" target="_blank" rel="noopener noreferrer">here</a>
</p>
